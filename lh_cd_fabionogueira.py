# -*- coding: utf-8 -*-
"""LH_CD_FabioNogueira.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GCCy4EAOeR4oMS3DFDgvfbV08-w5Qo4i
"""

!pip install scikit-learn
!pip install joblib

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from scipy import stats
import joblib
import warnings
warnings.filterwarnings('ignore')

pd.set_option('display.max_columns', None)

# Carregando os dados
df = pd.read_csv('teste_indicium_precificacao.csv')
print("Dados carregados com sucesso! Exibindo as primeiras linhas:")
display(df.head(3))

# Verificando dimensões do dataset
print(f"Dimensões do dataset: {df.shape}")

# Removendo colunas irrelevantes para análise
drop_columns = ['id', 'nome', 'host_id', 'host_name']
df.drop(columns=drop_columns, inplace=True)
print(f"Colunas removidas: {drop_columns}")

df.head(3)

# Verificando valores ausentes
display(df.isna().sum())

# Removendo colunas com muitos valores ausentes
drop_na_columns = ['ultima_review', 'reviews_por_mes']
df.drop(columns=drop_na_columns, inplace=True)
print(f"Colunas removidas por muitos valores ausentes: {drop_na_columns}")

display(df.head(3))

# Análise exploratória: Média de preço por bairro_group
df_grouped_bg = df[['bairro_group', 'price']].groupby('bairro_group').agg('mean').sort_values(by='price', ascending=False)
df_grouped_bg.reset_index(inplace=True)
display(df_grouped_bg)

# Calcular estatísticas descritivas do preço por 'bairro_group' e 'room_type'
stats_preco = df.groupby(['bairro_group', 'room_type'])['price'].agg(['mean', 'median', 'std']).reset_index()

# Renomear as colunas para manter o padrão desejado
stats_preco.columns = ['bairro_group', 'room_type', 'media_preco', 'mediana_preco', 'desvio_preco']

# Exibir o resultado
stats_preco

# Contagem de bairros
qtde_hosts = df['bairro_group'].value_counts()

# Gráfico de pizza com destaque para o maior grupo
explode_values = [0.1 if bairro == qtde_hosts.idxmax() else 0 for bairro in qtde_hosts.index]
plt.pie(qtde_hosts, labels=qtde_hosts.index, explode=explode_values, autopct='%1.1f%%')
plt.title('Proporção de Tipos de Quarto')
plt.show()

# Gráfico de barras para média de preço por bairro
plt.figure(figsize=(10,8))
sns.barplot(data=df, y='bairro_group', x='price')
plt.title('Média de Preço por Bairro')
plt.xlabel('Média de Preço')
plt.ylabel('Bairro Group')
plt.show()

# Gráfico de dispersão aprimorado
plt.figure(figsize=(10,8))
sns.scatterplot(data=df, x='price', y='minimo_noites', hue='bairro_group')
plt.title('Dispersão de Preço por Noites Mínimas')
plt.xlabel('Preço')
plt.ylabel('Noites Mínimas')
plt.show()

# Análise exploratória: Média de preço por room_type
df_grouped_rt = df[['room_type', 'price']].groupby('room_type').agg('mean').sort_values(by='price', ascending=False)
df_grouped_rt.reset_index(inplace=True)
display(df_grouped_rt)

# Gráfico de barras para média de preço por tipo de quarto
plt.figure(figsize=(10,8))
sns.barplot(data=df, y='room_type', x='price', palette='coolwarm')
plt.title('Média de Preço por Tipo de Quarto')
plt.xlabel('Média de Preço')
plt.ylabel('Tipo de Quarto')
plt.show()

# Histograma de preços com escala logarítmica
plt.figure(figsize=(10,6))
sns.histplot(df['price'], bins=50, kde=True, log_scale=True, color='blue')
plt.title('Distribuição de Preços (Escala Logarítmica)')
plt.xlabel('Preço')
plt.ylabel('Frequência')
plt.show()

# Selecionando colunas com tipos de dados numéricos
df_numerico = df.select_dtypes(include=[float, int])

# Calculando a matriz de correlação
correlation_matrix = df_numerico.corr()

# Correlação entre variáveis numéricas
plt.figure(figsize=(10,6))
sns.heatmap(df_numerico.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Mapa de Correlação entre Variáveis')
plt.show()

# Removendo outliers da variável 'price' usando IQR
Q1 = df['price'].quantile(0.25)
Q3 = df['price'].quantile(0.75)
IQR = Q3 - Q1
limite_inferior = Q1 - 1.5 * IQR
limite_superior = Q3 + 1.5 * IQR
df = df[(df['price'] >= limite_inferior) & (df['price'] <= limite_superior)]
print("Outliers removidos com sucesso!")
print(f"Dimensões do dataset após remoção de outliers: {df.shape}")

# Selecionar variáveis para modelagem
features = ['bairro_group', 'bairro', 'latitude', 'longitude', 'room_type', 'minimo_noites',
            'numero_de_reviews', 'calculado_host_listings_count', 'disponibilidade_365']
target = 'price'

# Separar features e target
X = df[features]
y = df[target]

# Dividir em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Identificar colunas numéricas e categóricas
num_features = ['latitude', 'longitude', 'minimo_noites', 'numero_de_reviews',
                'calculado_host_listings_count', 'disponibilidade_365']
cat_features = ['bairro_group', 'bairro', 'room_type']

# Pipeline de pré-processamento
preprocessor = ColumnTransformer([
    ('num', StandardScaler(), num_features),
    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)
])

# Criar pipeline para regressão linear
model = Pipeline([
    ('preprocessor', preprocessor),
    ('regressor', LinearRegression())
])

# Treinar modelo
model.fit(X_train, y_train)

# Fazer previsões
y_pred = model.predict(X_test)

# Avaliar modelo
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = mse ** 0.5
r2 = r2_score(y_test, y_pred)

print(f'MAE: {mae:.2f}')
print(f'RMSE: {rmse:.2f}')
print(f'R²: {r2:.2f}')

# Fazer a previsão do preço
y_pred = model.predict(X_test)
print(f'Preço previsto: ${y_pred[0]:.2f}')

# Salvar modelo
joblib.dump(model, 'modelo_precificacao.pkl')

from google.colab import files
files.download('modelo_precificacao.pkl')